\documentclass{article}

\usepackage{tikz} 
\usetikzlibrary{automata, positioning, arrows} 

\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{color}
\usepackage{parskip}
\usepackage{hyperref}
  \hypersetup{
    colorlinks = true,
    urlcolor = blue,       % color of external links using \href
    linkcolor= blue,       % color of internal links 
    citecolor= blue,       % color of links to bibliography
    filecolor= blue,        % color of file links
    }
    
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=haskell,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\newtheoremstyle{theorem}
  {\topsep}   % ABOVESPACE
  {\topsep}   % BELOWSPACE
  {\itshape\/}  % BODYFONT
  {0pt}       % INDENT (empty value is the same as 0pt)
  {\bfseries} % HEADFONT
  {.}         % HEADPUNCT
  {5pt plus 1pt minus 1pt} % HEADSPACE
  {}          % CUSTOM-HEAD-SPEC
\theoremstyle{theorem} 
   \newtheorem{theorem}{Theorem}[section]
   \newtheorem{corollary}[theorem]{Corollary}
   \newtheorem{lemma}[theorem]{Lemma}
   \newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
   \newtheorem{definition}[theorem]{Definition}
   \newtheorem{example}[theorem]{Example}
\theoremstyle{remark}    
  \newtheorem{remark}[theorem]{Remark}

\title{CPSC-354 Report}
\author{Rohm Tandon  \\ Chapman University}

\date{07/01/2024} 

\begin{document}

\maketitle 

\begin{abstract}
This report contains assignments throughout the fall 2024 semester and is intended for the purpose of documenting my work and showing my progress in CPSC 354 - Programming Languages, taught by Jonathan Weinberg.
\end{abstract}

\setcounter{tocdepth}{3}
\tableofcontents

\section{Introduction}\label{intro}

This report, prepared for CPSC 354 - Programming Languages at Chapman University, is a comprehensive account of my academic voyage over the semester. It includes a detailed compilation of my notes, homework solutions, and critical reflections on the coursework. This report serves as a bridge between the theoretical knowledge imparted in lectures and the practical skills essential for future pursuits in both graduate studies and the software industry.

\section{Week by Week}\label{homework}

\subsection{Week 1}

\subsubsection*{Notes}

In week 1 we learnt about Lean as a programming language and its correlation to discrete math. We also learnt about other proof assistants. We then shifted our focus to the NNG tutorial world as you can see below.

\subsubsection*{Homework}

Tutorial world 

Level 5: 
\includegraphics[width=0.5\textwidth]{Tutorial_level_5.png}

Discrete math's lemmas tell us that anything added to 0 will give the result of that number itself. So; A+0=A. 
Using this we can bring the left hand side down to a+b+c. 
From here we can use the property of reflexivity to show that both sides are equal, hence solving the puzzle. 

Level 6:
\includegraphics[width=0.5\textwidth]{Tutorial_level_6.png}

Level 7:
\includegraphics[width=0.5\textwidth]{Tutorial_level_7.png}

Level 8:
\includegraphics[width=0.5\textwidth]{Tutorial_level_8.png}


\subsection{Week 2}

\subsubsection*{Notes}

In week 2 we learnt about recursion and its application in other problems such as the Towers of Hanoi game we played. We also learnt about its various benefits such as breaking down complexity of problems and being more concise.

\subsubsection*{Homework}

Addition world

Level 1: 
\includegraphics[width=0.5\textwidth]{Addition_world_level_1.png}

Level 2: 
\includegraphics[width=0.5\textwidth]{Addition_world_level_2.png}

Level 3:
\includegraphics[width=0.5\textwidth]{Addition_world_level_3.png}

Level 4:
\includegraphics[width=0.5\textwidth]{Addition_world_level_4.png}

Using induction on c we can initially create an easier medium to use reflexivity to solve for a+b. Then solving the other side we just use the mathematical definiton of a successor function, until we can use the induction again to get the equation to the point where we can use reflexivity to prove it. This is a clear example of mathematical prrofs by induction.

Level 5:
\includegraphics[width=0.5\textwidth]{Addition_world_level_5.png}

Once again this is proof by mathematical induction similar to the previous one. This time we add the zeroes and then use reflexivity for the first part of the proof. Then to prove the second part we use the successor function until bringing back the induction we used like the previous question. Then to complete the proof we use reflexivity again. 

-

Discord Question: Since recursion has so many benefits and also breaks down the complexity of problems, why aren't we taught to use it as our primary method? In other words, why isn't it the first method of problem solving we're taught?

\subsection{Week 3}
\subsubsection*{Notes}
In week 3 we spoke about recursion further, and focused on our calculators in python. Eventually connecting the dots for our first Assignment that was due at the same time as Homework 4, where I used recursion in my python calculator in order to get it to function as efficiently as possible. We also discussed parsing, and derivation trees which is what we practiced in Homework 4.

\subsubsection*{Homework}
For homework 4 we did some practice on derivation trees for the strings you can see in the handwritten work below, along with the respective answers;

\includegraphics[width=0.5\textwidth]{HW4.JPG}

Discord Question: Why do programming languages need different types of parsers, and how does this choice impact the way a computer understands the code?

\subsection{Week 4}
\subsubsection*{Notes}
In week 4 we spoke about parsing and trees further which is what we practiced in last weeks Homework. But now we delved into the more notation heavy side of it. This weeks homework contained the lean logic game that helped us put some of that into practice.

\subsubsection*{Homework}
For homework 5 we completed the Lean logic game tutorial world. I have provided the answers to the same below. 

\begin{enumerate}
  \item \textbf{Exhibit evidence that you're planning a party.}

  \textbf{Level 1:}
  \begin{verbatim}
  example (P : Prop) (todo_list : P) : P := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact todo_list
  \end{verbatim}

  \textbf{Level 2:}
  \begin{verbatim}
  example (P S : Prop) (p : P) (s : S) : P ∧ S := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact and.intro p s
  \end{verbatim}

  \textbf{Level 3:}
  \begin{verbatim}
  example (A I O U : Prop) (a : A) (i : I) (o : O) (u : U) : (A ∧ I) ∧ O ∧ U := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  have ou := and_intro o u
  have ai := and_intro a i
  exact and_intro ai ou
  \end{verbatim}

  \textbf{Level 4:}
  \begin{verbatim}
  example (P S : Prop)(vm: P ∧ S) : P := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact vm.left
  \end{verbatim}

  \textbf{Level 5:}
  \begin{verbatim}
  example (P Q : Prop)(h: P ∧ Q) : Q := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact h.right
  \end{verbatim}

  \textbf{Level 6:}
  \begin{verbatim}
  example (A I O U : Prop)(h1 : A ∧ I)(h2 : O ∧ U) : A ∧ U := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact and_intro h1.left h2.right
  \end{verbatim}

  \textbf{Level 7:}
  \begin{verbatim}
  example (C L : Prop)(h: (L ∧ (((L ∧ C) ∧ L) ∧ L ∧ L ∧ L)) ∧ (L ∧ L) ∧ L) : C := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  have a:= h.left
  have b:= a.right
  have c:= b.left
  have d:= c.left
  exact d.right
  \end{verbatim}

  \textbf{Level 8:}
  \begin{verbatim}
  example (A C I O P S U : Prop)(h: ((P ∧ S) ∧ A) ∧ ¬I ∧ (C ∧ ¬O) ∧ ¬U) : A ∧ C ∧ P ∧ S := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  have a:=h.left
  have fin:=a.left
  have a:=a.right
  have r:=h.right
  have t:=r.right
  have k:= t.left
  have c:=k.left
  have e:= and_intro c fin
  exact and_intro a e
  

  Explanation for Solution 8: 

  We ultimately need A ∧ C ∧ P ∧ S, which means that we need to retrieve A, C, P, and S from the 
  original expression h. 

  (1) Seeing that A, P and S are on the left side of h-> extract h.left to get (P ∧ S) ∧ A.
  (2) Seeing that (P ∧ S) i already clearly made on the left side we can store (P ∧ S) together as 
      'fin' by extracting the left side.
  (3) Now from the same expression we can extract the right side to retrieve and store A as 'a'.
  (4) Now that we have A, P and S stored and easily accessible, we need C from right side of h.
  (5) After storing h.right in another expression, 'r', we take the right side of r to further 
      narrow down the position of C.
  (6) Now we take the left side of that expression for the same purpose, store it as k.
  (7) Finally we can retrieve C by storing the k.left as 'c'.
  (8) Now to finally present our solution we can start by using and_intro on c and fin, storing 
      that as e.
  (9) To complete our solution we use exact and_intro on a and e.


  \end{verbatim}
\end{enumerate}


Discord Question: How does the choice of a parsing technique (e.g., top-down vs. bottom-up) impact the efficiency and clarity of the resulting derivation tree? In other words, when should I choose between the two approaches so that my chosen approach is significantly more beneficial than the other?

\subsection{Week 5}
\subsubsection*{Notes}
In week 5 we spoke about type theory in programming languages. Moreover, we spoke about proposition types, constructive logic, and functional programming. We also furthered our understanding of the lean logic that helped me understand some parts of the homework as well.

\subsubsection*{Homework}
For homework 6 we completed the Lean logic game on implication. I have provided the answers to the same below. 

\begin{enumerate}
  \item \textbf{Exhibit evidence that cake will be delivered to the party}

  \textbf{Level 1:}
  \begin{verbatim}
  example (P C: Prop)(p: P)(bakery_service : P → C) : C := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact(bakery_service p)
  \end{verbatim}

  \textbf{Level 2:}
  \begin{verbatim}
  example (C: Prop) : C → C := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact λ h : C => h
  \end{verbatim}

  \textbf{Level 3:}
  \begin{verbatim}
  example (I S: Prop) : I ∧ S → S ∧ I := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact λ h : I ∧ S => and_intro (and_right h) h.left
  \end{verbatim}

  \textbf{Level 4:}
  \begin{verbatim}
  example (C A S: Prop) (h1 : C → A) (h2 : A → S) : C → S := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
    exact λ h : C => h2 (h1 h)
  \end{verbatim}

  \textbf{Level 5:}
  \begin{verbatim}
  example (P Q R S T U: Prop) (p : P) (h1 : P → Q) (h2 : Q → R) (h3 : Q → T) (h4 : S → T) 
  (h5 : T → U)
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact h5 ( h3 (  h1 p))
  \end{verbatim}

  \textbf{Level 6:}
  \begin{verbatim}
  example (C D S: Prop) (h : C ∧ D → S) : C → D → S := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact fun f : C => fun b : D => h ⟨f, b⟩
  \end{verbatim}

  \textbf{Level 7:}
  \begin{verbatim}
  example (C D S: Prop) (h : C → D → S) : C ∧ D → S := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact fun f : C ∧ D => h f.left f.right
  \end{verbatim}

  \textbf{Level 8:}
  \begin{verbatim}
  example (C D S : Prop) (h : (S → C) ∧ (S → D)) : S → C ∧ D := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact fun s : S => and_intro (h.left s) (  h.right s)
  \end{verbatim}

  \textbf{Level 9:}
  \begin{verbatim}
  example (R S : Prop) : R → (S → R) ∧ (¬S → R) := by
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  exact fun r : R => and_intro (fun s : S => r) (  fun ss: ¬S => r)
  \end{verbatim}
\end{enumerate}

Discord Question: How can implication be used in functional programming, and more so, why is it not as seemingly embedded in some of the popular languages we use today?

\subsection{Week 6}
\subsubsection*{Notes}
In week 6 we spoke about Lambda Reduction and practiced a few questions to improve our understanding of the same.

\subsubsection*{Homework}
For homework 7 we discussed some theory related to capture avoiding substitution by reducing a lambda term. Then we read and discussed Church numerals.

\begin{enumerate}
  \item \textbf{ The purpose of this hw is to practice capture avoiding substitution. }
  
  \textbf{Question 1:}
  \begin{Reduce the following lambda term: ((\m.\n.mn)(\f.\x.f(fx)))(\f.\x.f(f(fx)))}
  
  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  - (\n.(\f.\x.f(fx))n)(\f.\x.f(f(fx)))
  - (\f.\x.f(fx))(\f.\x.f(f(fx)))
  - \x.((\f.\x.f(f(fx)))(f(fx)))

  Capture avoiding substitution is the practice of performing substitutions in lambda calculus, 
  while ensuring that no variables are "captured" by new bindings. In other words, if we 
  substitute a variable in an expression, we should not accidentally bind it to a lambda term 
  that already uses that variable in a different scope.
  This yields the result: \x.((\f.\x.f(f(fx)))((\f.\x.f(f(fx)))x))
  \end{verbatim}

  \textbf{Question 2:}
  \begin{ Explain what function on natural numbers (\m. \n. m n) implements.}

  \end{verbatim}

  \textbf{Solution:}
  \begin{verbatim}
  
    Given \m.\n.mn, let's interpret it in terms of Church numerals.
    This function takes two Church numerals, m and n.
    This function implements addition for Church numerals. It combines the number of applications 
    of f in m and n, resulting in m + n.
    So this function represents the addition function in Church numerals.

  \end{verbatim}

\end{enumerate}

Discord Question: When performing capture-avoiding substitution, we often rename bound variables to avoid conflicts. How might this affect the efficiency or complexity of the substitution operation?

\subsection{Week 7}
\subsubsection*{Notes}
In week 7 we spoke more about beta reduction and dove into reducing expressions with Church numerals. Overall, we went over Turing completeness and the connection between that and our previous topic of Church numerals.


\subsection{Week 8}
\subsubsection*{Notes}
In week 8 we spoke about different reduction strategies - by value and by name. We also looked at the VSCode debugger and learnt about the importance of working with a debugger. We then tried to understand the interpreter and then used our learning of the different reduction strategies in our homework.

\subsubsection*{Homework}
For homework 8-9 we did Exercises 2-8 in https://hackmd.io/@alexhkurz/S1R1F6_1yx

2) For a b c d, the reduction occurs in a left-associative manner: a b c d → (((a b) c) d). Each application applies the leftmost term to the next in sequence, creating nested applications.
   For (a), it's a single variable wrapped in parentheses, which reduces to a as there are no further applications or abstractions.

3) Capture-avoiding substitution ensures that when substituting a variable, it doesn't inadvertently capture free variables.
   This involves renaming bound variables to prevent conflicts, a common issue in lambda calculus interpreters.
   The substitute function receives three parameters: The expression in which substitution occurs, the variable being replaced, and the expression replacing the variable.
   For application expressions (e.g., a b), it recursively applies substitution to both the function and argument. The Lambda abstraction is where the capture avoiding substitution comes into play.
   The interpreter checks for conflicts, and a fresh variable name is generated to replace the conflicting bound variable. After renaming, substitution proceeds within the lambda body with the newly renamed variable.

4) Generally, the interpreter provides the expected results when handling basic lambda expressions and straightforward applications. However, more complex expressions with multiple nested applications or ones that involve intricate substitutions may sometimes yield unexpected results if there are any implementation issues with capture-avoiding substitution or recursive application handling.
   Not all computations reduce to normal form. Some expressions, particularly those involving self-application lead to infinite loops because they lack a terminating condition.
   For other expressions designed to terminate, like Church numerals in basic operations, the interpreter generally reaches normal form as expected.

5) An example of such an expression is the "omega combinator" 
\begin{verbatim} ((\x. x x) (\x. x x)) \end{verbatim} 
   which results in an infinite loop of self-application.
   I added this to test.lc to observe this non-terminating behaviour in order to identify it as the MWE.

6) I followed the instruction as per, for the next two items.

7) The substitutions were seen at the breakpoints. A concise version of the same is below;
    \begin{verbatim}
      (\n.(m n))
      (m n)
      (m Var1)
      ((\f.(\x.(f (f x)))) Var1)
      (\f.(\x.(f (f x))))
      (f (f x))
      (f (f Var3))
      (\Var3.(Var2 (Var2 Var3)))
      (Var2 (Var2 Var3))
      (Var2 Var3)
      (Var2 (Var2 Var4))
      (\Var4.(Var2 (Var2 Var4)))
      (Var2 (Var2 Var4))
      (Var2 (Var2 Var5))
    \end{verbatim}

8) The trace is written out below;
    \begin{verbatim}
      13 (((\m.(\n.(m n))) (\f.(\x.(f (f x))))) (\f.(\x.(f (f (f x))))))
        40 ((\m.(\n.(m n))) (\f.(\x.(f (f x)))))
        40 (\m.(\n.(m n)))
          54 ((\m.(\n.(m n))) (\f.(\x.(f (f x)))))
            46 (\Var1.((\f.(\x.(f (f x)))) Var1))
              54 ((\m.(\n.(m n))) (\f.(\x.(f (f x)))))
              54 (((\m.(\n.(m n))) (\f.(\x.(f (f x))))) (\f.(\x.(f (f (f x))))))
            46 ((\Var2.(\Var4.(Var2 (Var2 Var4)))) (\f.(\x.(f (f (f x))))))
        40 (\Var2.(\Var4.(Var2 (Var2 Var4))))
          54 ((\Var2.(\Var4.(Var2 (Var2 Var4)))) (\f.(\x.(f (f (f x))))))
            46 (\Var5.((\f.(\x.(f (f (f x))))) ((\f.(\x.(f (f (f x))))) Var5)))
          54 ((\Var2.(\Var4.(Var2 (Var2 Var4)))) (\f.(\x.(f (f (f x))))))
          54 (((\m.(\n.(m n))) (\f.(\x.(f (f x))))) (\f.(\x.(f (f (f x))))))
    \end{verbatim}

Discord Question: Capture avoiding substitution seems to be a fundamental theme to lambda calculus interpreters, but I still have problems understanding how to best implement it in Python. What other resources can I use to further understand its implementation?

\subsection{Week 9}
\subsubsection*{Notes}
In week 9 we continued to speak about the interpreter and modifying it. We also read about three languages - BLOOP, FLOOP, and GLOOP in order to further our understanding of recursion. 

\subsubsection*{Homework}
For homework 10 we reflected on the previous week's homework: 8-9, as well as our group programming assignment 3. My reflection is given below.

1) I found keeping track of the trace was one of the most challenging parts of the homework. I was not completely sure of where exactly my breakpoints needed to be for exercise 7 and I had to do it multiple times to formulate a readable answer. However, this helped me understand what exctly was happening through the debugging process.
2) We took our time with the exercise and then spoke about it as a group before coming up with our key insight, realising that our evaluation strategy really matters.
3) My most intersting takeaway is that despite python being my most used language, there are still some seemingly necessary things that I am not aware of. I certainly want to master using these skills in order to be able to use them in my day to day coding. I rely on print statements more than I apparently should, and that is something I would have never expected to find out this way.

Discord Question: Many developers rely on print statements, but it seems like breakpoints and the debug console can provide more control and insight. What is the best way to make the switch over to using those, and should I completely stop relying on print statements?

\subsection{Week 10}
\subsubsection*{Notes}
In week 10 we spoke about Algorithms as Rewriting Systems (ARSs) and the homework reflects exercises regarding the same.

\subsubsection*{Homework}
For homework 11 we worked on ARSs given a list to work with. my work for the same is below.

\textbf{Question:}

For each of the 8 possible combinations of the properties confluent (\( C \)), terminating (\( T \)), and having unique normal forms (\( UNF \)), determine whether such an ARS exists. Provide an example if possible, or explain why it cannot exist. For the examples, draw the ARS diagrams.

\textbf{Answer:}

\textbf{1. Confluent: True, Terminating: True, Unique Normal Forms: True}

\textit{Example:}

Consider the ARS with elements \( S = \{ a, b, c \} \) and reduction rules:

\[
  a \to b, \quad b \to c
\]

\textit{Diagram:}

\begin{center}
  \begin{tikzpicture}[node distance=2cm, ->, >=stealth, auto]
    \node (A) {\( a \)};
    \node (B) [right of=A] {\( b \)};
    \node (C) [right of=B] {\( c \)};
    \draw (A) to (B);
    \draw (B) to (C);
  \end{tikzpicture}
\end{center}

\textit{Analysis:}

- \textbf{Terminating:} Yes, all reduction sequences eventually reach \( c \), which is a normal form.
- \textbf{Confluent:} Yes, there are no diverging reduction paths.
- \textbf{Unique Normal Forms:} Yes, every element reduces to \( c \), the unique normal form.


\textbf{2. Confluent: True, Terminating: True, Unique Normal Forms: False}

\textit{Explanation:}

This combination is \textbf{impossible}. In a confluent and terminating ARS, every element reduces to a unique normal form. Therefore, unique normal forms must exist.


\textbf{3. Confluent: True, Terminating: False, Unique Normal Forms: True}

\textit{Example:}

Consider the ARS \( S = \{ a, b, c \} \) and rules:

\[
  a \to b, \quad b \to a, \quad a \to c, \quad b \to c
\]

\textit{Diagram:}

\begin{center}
  \begin{tikzpicture}[node distance=2cm, ->, >=stealth, auto]
    \node (A) {\( a \)};
    \node (B) [right of=A] {\( b \)};
    \node (C) [below of=A, node distance=1.5cm] {\( c \)};
    \draw (A) to (B);
    \draw (B) to (A);
    \draw (A) to (C);
    \draw (B) to (C);
  \end{tikzpicture}
\end{center}

\textit{Analysis:}

- \textbf{Terminating:} No there is an infinite loop between \( a \) and \( b \)
- \textbf{Confluent:} Yes, both \( a \) and \( b \) reduce to \( c \), and any divergent paths converge at \( c \).
- \textbf{Unique Normal Forms:} Yes, all elements reduce to \( c \), the unique normal form.


\textbf{4. Confluent: True, Terminating: False, Unique Normal Forms: False}

\textit{Example:}

Consider the ARS with elements \( S = \{ a, b \} \) and rules:

\[
  a \to b, \quad b \to a
\]

\textit{Diagram:}

\begin{center}
  \begin{tikzpicture}[node distance=2cm, ->, >=stealth, auto]
    \node (A) {\( a \)};
    \node (B) [right of=A] {\( b \)};
    \draw (A) to (B);
    \draw (B) to (A);
  \end{tikzpicture}
\end{center}

\textit{Analysis:}

- \textbf{Terminating:} No, there is an infinite loop between \( a \) and \( b \).
- \textbf{Confluent:} Yes, there are no diverging paths; the reductions cycle between \( a \) and \( b \).
- \textbf{Unique Normal Forms:} No, neither \( a \) nor \( b \) is a normal form, and there are no normal forms in \( S \).


\textbf{5. Confluent: False, Terminating: True, Unique Normal Forms: True}

\textit{Explanation:}

This combination is \textbf{impossible}. If an ARS has unique normal forms, it must be confluent.


\textbf{6. Confluent: False, Terminating: True, Unique Normal Forms: False}

\textit{Example:}

Consider the ARS \( S = \{ a, b, c \} \) and rules:

\[
  a \to b, \quad a \to c
\]

\textit{Diagram:}

\begin{center}
  \begin{tikzpicture}[->, >=stealth, auto]
    \node (A) at (0,0) {\( a \)};
    \node (B) at (2,1) {\( b \)};
    \node (C) at (2,-1) {\( c \)};
    \draw (A) to (B);
    \draw (A) to (C);
  \end{tikzpicture}
\end{center}

\textit{Analysis:}

- \textbf{Terminating:} Yes, reductions terminate at \( b \) or \( c \), which are normal forms.
- \textbf{Confluent:} No, from \( a \), we can reach two different normal forms, \( b \) and \( c \), which are not joinable.
- \textbf{Unique Normal Forms:} No, the element \( a \) has two distinct normal forms.


\textbf{7. Confluent: False, Terminating: False, Unique Normal Forms: True}

\textit{Explanation:}

This combination is \textbf{impossible}. Unique normal forms imply that the ARS is confluent and normalising.


\textbf{8. Confluent: False, Terminating: False, Unique Normal Forms: False}

\textit{Example:}

Consider the ARS with elements \( S = \{ a, b, c \} \) and rules:

\[
  a \to b, \quad b \to a, \quad a \to c
\]

\textit{Diagram:}

\begin{center}
  \begin{tikzpicture}[->, >=stealth, auto]
    \node (A) at (0,1) {\( a \)};
    \node (B) at (2,1) {\( b \)};
    \node (C) at (1,0) {\( c \)};
    \draw (A) to (B);
    \draw (B) to (A);
    \draw (A) to (C);
  \end{tikzpicture}
\end{center}

\textit{Analysis:}

- \textbf{Terminating:} No, there is an infinite loop between \( a \) and \( b \).
- \textbf{Confluent:} No, from \( a \), we can either loop indefinitely between \( a \) and \( b \), or reduce to \( c \).
- \textbf{Unique Normal Forms:} No, \( c \) is a normal form reachable from \( a \), but \( b \) and \( a \) do not reduce to \( c \) if we stay in the loop.

Discord Question: In what real-world applications would rewriting systems provided unique advantages over other types of algorithms?

\subsection{Week 11}
\subsubsection*{Notes}
In week 11 we covered some string rewriting exercises while talking about operational and denotational semantics.

\subsubsection*{Homework}
For homework 12 we put our methodical learning into practice in order to learn the method of decidability via rewriting to normal form and the method of invariants. Questions 1- 5b were assigned for this.

\textbf{Exercise 1:}
\begin{verbatim}
The rewrite rule is:
  ba -> ab
a) Why does the ARS terminate?
b) What is the result of a computation (the normal form)?
c) Show that the result is unique (the ARS is confluent).
d) What specification does this algorithm implement?
\end{verbatim}

\textbf{Answer 1:}
\begin{verbatim}
a) Each rewrite ba->ab reduces disorder. The string is finite, so rewriting stops when no ba remains.
b) The normal form is the string in which all occurrences of b appear after all occurrences of a.
c) The ARS is confluent if for any string, all rewriting sequences eventually lead to the same final 
   result (normal form). Here, the system is confluent because no matter how the rule ba->ab is applied, 
   the final result will always be the lexicographically ordered string because the rewrite rule 
   consistently moves a's to the left and b's to the right.
d) This algorithm implements sorting, placing all a's before all b's.
\end{verbatim}

\textbf{Exercise 2:}
\begin{verbatim}
Rewrite rules are
  aa -> a
  bb -> a
  ab -> b
  ba -> b 
a) Why does the ARS terminate?
b) What are the normal forms?
c) Is there a string s that reduces to both a and b?
d) Show that the ARS is confluent.
The next questions have all essentially the same answer:
e) Replacing -> by =, which words become equal?
f) Can you describe the equality = without making reference to the four rules above?
g) Can you repeat the last item using modular arithmetic?
h) Which specification does the algorithm implement?
\end{verbatim}

\textbf{Answer 2:}
\begin{verbatim}
a) The rewriting rules reduce the string's length, as every rewrite replaces two characters with one, 
   eventually causing it to terminate.
b) The normal forms are a and b as no rewrite rules apply to a single character.
c) No, this does not exist.
d) The ARS is confluent because, regardless of the rewrite order, all reduction paths lead to the same 
   unique normal form.
e) Any two strings reduce to the same normal form (a or b), so they are equal under this equivalence 
   relation.
f) Two strings are equivalent if their counts of a and b modulo 2 are the same.
g) A string's equivalence is determined by the count of a mod 2 and the count of b mod 2. Strings with 
   the same parities of a and b are equal.
h) It implements a parity check on the counts of a and b, reducing strings to one of two equivalence 
   classes: a or b.
\end{verbatim}

\textbf{Exercise 3:}
\begin{verbatim}
Rewrite rules are
  aa -> a
  bb -> b
  ba -> ab
  ab -> ba
a) Why does the ARS not terminate?
b) What are the normal forms?
c) Modify the ARS so that it is terminating, has unique normal forms (and still the same equivalence 
   relation).
d) Describe the specification implemented by the ARS.
\end{verbatim}

\textbf{Answer 3:}
\begin{verbatim}
a} The rules ba -> ab and ab -> ba create an infinite loop because they allow back-and-forth rewriting
   without reducing the length or modifying the structure of the string.
b) The ARS does not have normal forms because it can endlessly rewrite ab and ba without reaching a 
   stable state.
c) The modified rules would be;
   aa -> a
   bb -> b
   ba -> ab
d) The ARS implements lexicographical sorting of a and b, while reducing sequences of identical 
   characters to a single character. It achieves the equivalence relation where strings with the same 
   counts of a and b reduce to the same normal form.
\end{verbatim}

\textbf{Exercise 4:}
\begin{verbatim}
Rewrite rules are
  ab -> ba
  ba -> ab
Same questions as above. (This is a variation of Exse 1.)
\end{verbatim}

\textbf{Answer 4:}
\begin{verbatim}
a) The rules ba -> ab and ab -> ba create an infinite loop because they allow back-and-forth rewriting
   without reducing the length or modifying the structure of the string.
b) There are no normal forms because the ARS does not terminate, due to the same reason.
c) The modified rules would be;
   ab -> ba
d) The ARS implements a lexicographical ordering of the string by sorting ab to ba. It ensures that all 
   strings end in the lexicographically smaller arrangement of a and b.
\end{verbatim}

\textbf{Exercise 5:}
\begin{verbatim}
Consider the rewrite rules
  ab -> ba
  ba -> ab
  aa ->
  b ->
a) Reduce some example strings such as abba and bababa.
b) Why is the ARS not terminating?
c) How many equivalence classes does ⟷* have? Can you describe them in a nice way? What are the normal 
   forms?
   [Hint: It may be easier to first answer the next question.]
d) Can you change the rules so that the ARS becomes terminating without changing its equivalence
   classes?
e) Write down a question or two about strings that can be answered using the ARS. Think about whether 
   this 
   amounts to giving a semantics to the ARS.
   [Hint: The best answers are likely to involve a complete invariant.]
\end{verbatim}

\textbf{Answer 5:}
\begin{verbatim}
a) They both loop indefinitely as you can see; abba->ab -> ba -> ab..., bababa->bab -> aba -> bab...
b) The rules ba -> ab and ab -> ba create an infinite loop because they allow back-and-forth rewriting
   without reducing the length or modifying the structure of the string.
c) There are 4 equivalence classes based on these modulo counts:
   (0, 0) - Even count of both a and b.
   (1, 0) - Odd a, even b.
   (0, 1) - Even a, odd b.
   (1, 1) - Odd a and b.
   The normal forms are strings reduced to either the empty string (if aa -> and b -> apply fully) or  
   a single character representing the final parity:
   a for (1, 0)
   b for (0, 1)
   ab or ba for (1, 1)
   Empty string for (0, 0).
d) Yes, firstly I would remove the ab->ba and ba->ab rules and use;
   aa ->
   b ->
   ab ->
e) Q1. Does the string have an odd or even number of a's and b's?
   Q2. What is the equivalence class of a given string?
\end{verbatim}

\textbf{Exercise 5b:}
\begin{verbatim}
As Exse 5, but change aa -> to aa -> a.
\end{verbatim}

\textbf{Answer 5b:}
\begin{verbatim}
a) They both loop indefinitely as you can see; abba -> ab -> ba -> ab..., bababa->bab -> aba -> bab...
b) The rules ba -> ab and ab -> ba create an infinite loop because they allow back-and-forth rewriting
   without reducing the length or modifying the structure of the string.
c) The equivalence classes remain the same as in Exse 5, as the new rule does not affect the 
   equivalence relation.
   With the modified rule aa -> a, the normal forms are:
    a for (1, 0)
    b for (0, 1)
    ab or ba for (1, 1) (depending on how the cycle is resolved).
    Empty string for (0, 0).
d) Yes, firstly I would remove the ab->ba and ba->ab rules and use;
   aa -> a
   b ->
e) Q1. Does the string have an odd or even count of as or bs?
   Q2. What is the smallest lexicographical representative of the string's equivalence class?
\end{verbatim}

Discord Question: Are rules like ab -> ba and ba -> ab that create infinite loops ever useful, or should they always be avoided? So far most of our work with them has been related to replacing them to create terminating ARSs.

\section{Lessons from the Assignments}


\section{Conclusion}\label{conclusion}


\begin{thebibliography}{99}
\bibitem[BLA]{bla} Author, \href{https://en.wikipedia.org/wiki/LaTeX}{Title}, Publisher, Year.
\end{thebibliography}

\end{document}
